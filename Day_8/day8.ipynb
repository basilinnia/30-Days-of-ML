{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Leakage\n",
    "\n",
    "Data Leakage is the scenario where the Machine Learning Model is already aware of some part of test data after training.This causes the problem of overfitting. <br> <br>\n",
    "\n",
    "In Machine learning, Data Leakage refers to a mistake that is made by the creator of a machine learning model in which they accidentally share the information between the test and training data sets. Typically, when splitting a data set into testing and training sets, the goal is to ensure that no data is shared between these two sets. Ideally, there is no intersection between these two sets. This is because the purpose of the testing set is to simulate the real-world data which is unseen to that model. However, when evaluating a model, we do have full access to both our train and test sets, so it is our duty to ensure that there is no overlapping between the training data and the testing data (i.e, no intersection). <br><br>\n",
    "\n",
    "In other words, leakage causes a model to look accurate until you start making decisions with the model, and then the model becomes very inaccurate.\n",
    "\n",
    "There are two main types of leakage: target leakage and train-test contamination. <br><br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target leakage\n",
    "Target leakage occurs when your predictors include data that will not be available at the time you make predictions. It is important to think about target leakage in terms of the timing or chronological order that data becomes available, not merely whether a feature helps make good predictions. <br>\n",
    "\n",
    "![](tl_1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Contamination\n",
    "A different type of leak occurs when you aren't careful to distinguish training data from validation data. <br><br>\n",
    "\n",
    "Recall that validation is meant to be a measure of how the model does on data that it hasn't considered before. You can corrupt this process in subtle ways if the validation data affects the preprocessing behavior. This is sometimes called train-test contamination : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataset: 1319\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reports</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>share</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>owner</th>\n",
       "      <th>selfemp</th>\n",
       "      <th>dependents</th>\n",
       "      <th>months</th>\n",
       "      <th>majorcards</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37.66667</td>\n",
       "      <td>4.5200</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>124.983300</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>33.25000</td>\n",
       "      <td>2.4200</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>9.854167</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>33.66667</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>30.50000</td>\n",
       "      <td>2.5400</td>\n",
       "      <td>0.065214</td>\n",
       "      <td>137.869200</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>32.16667</td>\n",
       "      <td>9.7867</td>\n",
       "      <td>0.067051</td>\n",
       "      <td>546.503300</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reports       age  income     share  expenditure  owner  selfemp  \\\n",
       "0        0  37.66667  4.5200  0.033270   124.983300   True    False   \n",
       "1        0  33.25000  2.4200  0.005217     9.854167  False    False   \n",
       "2        0  33.66667  4.5000  0.004156    15.000000   True    False   \n",
       "3        0  30.50000  2.5400  0.065214   137.869200  False    False   \n",
       "4        0  32.16667  9.7867  0.067051   546.503300   True    False   \n",
       "\n",
       "   dependents  months  majorcards  active  \n",
       "0           3      54           1      12  \n",
       "1           3      34           1      13  \n",
       "2           4      58           1       5  \n",
       "3           0      25           1       7  \n",
       "4           2      64           1       5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data\n",
    "data = pd.read_csv('./credit_card_data.csv',true_values=['yes'], false_values=['no'])\n",
    "\n",
    "# Select target\n",
    "y = data.card\n",
    "\n",
    "# Select predictors\n",
    "X = data.drop(['card'], axis=1)\n",
    "\n",
    "print(\"Number of rows in the dataset:\", X.shape[0])\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy: 0.981052\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Since there is no preprocessing, we don't need a pipeline (used anyway as best practice!)\n",
    "my_pipeline = make_pipeline(RandomForestClassifier(n_estimators=100))\n",
    "cv_scores = cross_val_score(my_pipeline, X, y,cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-validation accuracy: %f\" % cv_scores.mean())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With experience, you'll find that it's very rare to find models that are accurate 98% of the time. It happens, but it's uncommon enough that we should inspect the data more closely for target leakage.\n",
    "\n",
    "Here is an unordered list of variables along with their brief description:\n",
    "\n",
    "- **card**: Binary variable indicating whether the credit card application was accepted (1) or not (0).\n",
    "- **reports**: Number of major derogatory reports.\n",
    "- **age**: Age in years plus twelfths of a year.\n",
    "- **income**: Yearly income divided by 10,000.\n",
    "- **share**: Ratio of monthly credit card expenditure to yearly income.\n",
    "- **expenditure**: Average monthly credit card expenditure.\n",
    "- **owner**: Binary variable indicating whether the applicant owns a home (1) or rents (0).\n",
    "- **selfempl**: Binary variable indicating whether the applicant is self-employed (1) or not (0).\n",
    "- **dependents**: Number of dependents.\n",
    "- **months**: Number of months the applicant has been living at their current address.\n",
    "- **majorcards**: Number of major credit cards held.\n",
    "- **active**: Number of active credit accounts.  <br> <br>\n",
    "A few variables look suspicious. For example, does expenditure mean expenditure on this card or on cards used before applying?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a data comparison to see it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of those who did not receive a card and had no expenditures: 1.00\n",
      "Fraction of those who received a card and had no expenditures: 0.02\n"
     ]
    }
   ],
   "source": [
    "expenditures_cardholders = X.expenditure[y]\n",
    "expenditures_noncardholders = X.expenditure[~y]\n",
    "\n",
    "print('Fraction of those who did not receive a card and had no expenditures: %.2f' %((expenditures_noncardholders == 0).mean()))\n",
    "print('Fraction of those who received a card and had no expenditures: %.2f' %(( expenditures_cardholders == 0).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-val accuracy: 0.833958\n"
     ]
    }
   ],
   "source": [
    "# Drop leaky predictors from dataset\n",
    "potential_leaks = ['expenditure', 'share', 'active', 'majorcards']\n",
    "X2 = X.drop(potential_leaks, axis=1)\n",
    "\n",
    "# Evaluate the model with leaky predictors removed\n",
    "cv_scores = cross_val_score(my_pipeline, X2, y, cv=5,scoring='accuracy')\n",
    "\n",
    "print(\"Cross-val accuracy: %f\" % cv_scores.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data leakage refers to a situation where information that is not available at the time of prediction is used to create a machine learning model. In this case, potential_leaks ['expenditure', 'share', 'active', 'majorcards'] are predictors that are not available at the time of prediction, and hence they are considered leaky predictors. This is because they represent information that would only be known after the credit card application has been approved, and hence it would not be useful in predicting the approval outcome. <br><br>\n",
    "\n",
    "If these leaky predictors were included in the model, they would have provided extra information that could have resulted in overfitting and overly optimistic accuracy estimates. Hence, it is essential to remove such leaky predictors before creating a machine learning model to ensure that the model is accurate and reliable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply it says, if diabetes (the target) depends on the your sugar_level data, but you don't have that info right now for a patient which you have to predict its condition, it can cause a leakage in the data which results for your model just fits the given set. If the model was created with the sugar level data, it would fit the given set too closely, and it may not perform well when it is used to predict the target for new patients. Therefore, it is essential to avoid using such leaky predictors to ensure that the model is not biased and can accurately predict the target outcome for new data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
