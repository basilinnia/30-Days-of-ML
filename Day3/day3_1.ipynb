{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with missing values\n",
    "We are going to work on three approaches to dealing with the missing values in a dataset. These are: <br>\n",
    "1. Dropping Columns with Missing Values\n",
    "2. Imputation (basically we're just filling the empty value, for example we can fill in the mean value along each column)\n",
    "3. An Extension To Imputation (but the value we delete was special for the dataset, so we're adding a new column that shows the location of the imputed entries) <br>\n",
    "\n",
    "## Here is how we use it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "melb_data = pd.read_csv('./melb_data.csv')\n",
    "\n",
    "# what we want to predict\n",
    "y = melb_data.Price\n",
    "\n",
    "predictors = melb_data.drop([\"Price\"], axis=1)\n",
    "X = predictors.select_dtypes(exclude=\"object\")\n",
    "\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=1)\n",
    "\n",
    "def score_dataset(train_X, valid_X, train_y, valid_y):\n",
    "    model = RandomForestRegressor(n_estimators=10, random_state=1)\n",
    "    model.fit(train_X, train_y)\n",
    "    y_pred = model.predict(valid_X)\n",
    "    mae = mean_absolute_error(valid_y, y_pred)\n",
    "    return mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10864, 12)\n",
      "Car               52\n",
      "BuildingArea    5193\n",
      "YearBuilt       4312\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Shape of training data (num_rows, num_columns)\n",
    "print(train_X.shape)\n",
    "\n",
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (train_X.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Approach: Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_columns = [col for col in train_X.columns if train_X[col].isnull().any()]\n",
    "reduced_X_train = train_X.drop(missing_columns, axis=1)\n",
    "reduced_X_valid = valid_X.drop(missing_columns, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd Approach: Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(train_X))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(valid_X))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_X_train.columns = train_X.columns\n",
    "imputed_X_valid.columns = valid_X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1041     False\n",
      "1989     False\n",
      "10157    False\n",
      "1711     False\n",
      "11565    False\n",
      "         ...  \n",
      "905      False\n",
      "5192     False\n",
      "12172    False\n",
      "235      False\n",
      "13349    False\n",
      "Name: Car_was_missing, Length: 10864, dtype: bool\n",
      "1041     False\n",
      "1989     False\n",
      "10157     True\n",
      "1711     False\n",
      "11565     True\n",
      "         ...  \n",
      "905      False\n",
      "5192      True\n",
      "12172    False\n",
      "235       True\n",
      "13349     True\n",
      "Name: BuildingArea_was_missing, Length: 10864, dtype: bool\n",
      "1041     False\n",
      "1989     False\n",
      "10157     True\n",
      "1711     False\n",
      "11565     True\n",
      "         ...  \n",
      "905      False\n",
      "5192      True\n",
      "12172    False\n",
      "235       True\n",
      "13349     True\n",
      "Name: YearBuilt_was_missing, Length: 10864, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Make copy to avoid changing original data (when imputing)\n",
    "X_train_plus = train_X.copy()\n",
    "X_valid_plus = valid_X.copy()\n",
    "\n",
    "# Make new columns indicating what will be imputed\n",
    "for col in missing_columns:\n",
    "    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n",
    "    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n",
    "\n",
    "# Imputation\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\n",
    "imputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_X_train_plus.columns = X_train_plus.columns\n",
    "imputed_X_valid_plus.columns = X_valid_plus.columns\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1:\n",
      "187082.57548478153\n",
      "MAE from Approach 2:\n",
      "174917.69150711832\n",
      "MAE from Approach 3:\n",
      "177346.30320324007\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 1:\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_valid, train_y, valid_y))\n",
    "print(\"MAE from Approach 2:\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, train_y, valid_y))\n",
    "print(\"MAE from Approach 3:\")\n",
    "print(score_dataset(imputed_X_train_plus, imputed_X_valid_plus,  train_y, valid_y))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, approach 2 better for our dataset. The training data has 10864 rows and 12 columns, where three columns contain missing data. For each column, less than half of the entries are missing. Thus, dropping the columns removes a lot of useful information, and so it makes sense that imputation would perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10864, 9)\n",
      "3\n",
      "Car               52\n",
      "BuildingArea    5193\n",
      "YearBuilt       4312\n",
      "dtype: int64\n",
      "total:  9557\n"
     ]
    }
   ],
   "source": [
    "# Shape of training data (num_rows, num_columns)\n",
    "print(reduced_X_train.shape)\n",
    "\n",
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (train_X.isnull().sum())\n",
    "print(train_X.isnull().any().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0.0])\n",
    "print(\"total: \", train_X.isnull().sum().sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
